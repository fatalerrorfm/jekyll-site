Speaker A
Artichoke pizza. If you had artichoke pizza while you're here.

Speaker B
I mean, I've had I know I've had pizza, like, with artichokes on it. Is this a specific?

Speaker A
No, it's a place. And they have an artichoke pizza. It's very large, it's creamy, has spinach, artichoke, gouda cheese, that kind of thing on it. You probably had this type of pizza before.

Speaker B
I don't think I've had this specific. Um right. We're just like photos of the pizza. Is that not something we can I click on latest Instagram, and that doesn't really take me anywhere.

Speaker A
Type in artichoke. Basilis. B-A-S-I-L-L-E. Let's see.

Speaker B
I'm just going to do a Google image search here.

Speaker A
Yeah, that's your best bet.

Speaker B
This looks good.

Speaker A
It's really good. Although there are apparently New York pizza purists who say that it's not real new York pizza.

Speaker B
Looks like kind of a thicker crust for New York pizza.

Speaker A
Well, that's the thing, is there's an artichoke slice, which is very, very bready, but then there's a margarita, which I think has a really great deep flavor. And then there's also something called the grandma slice, which is like a Sicilian cut, which I think also has a really great flavor. I actually hardly eat the artichoke, but it's good to have at least once.

Speaker B
The Sicilian cut is more of a, like, New York style. Right?

Speaker A
Kind of. It's still thick and it's almost burned on the bottom, which I actually really like, but some people don't. It's not your classic foldable pizza, I would say. Yeah.

Speaker B
Recently, I feel like Detroit style pizza is a term that I've heard more and more, and I think that's just like your it's not New York style pizza. It's not really foldable. There's more bread to it, but it's certainly not deep dish pizza either. It's just like your sort of average American pizza.

Speaker A
I don't know if I would call it average American pizza because it's square and the sauce is on top.

Speaker B
That's true. The square is, I guess, the sauce, too. Yeah. I don't know. It's a weird term.

Speaker A
Weird slice.

Speaker B
I'd only heard man. Yeah. That looks like an intense picture from Business Insider. It's just sauce all over.

Speaker A
Have you had a Detroit style pizza in Detroit?

Speaker B
I don't think I've actually had it in Detroit. No, in Ann Arbor.

Speaker A
In Ann Arbor. I mean, that counts, right? Ann Arbor is, like 30 minutes from Detroit.

Speaker B
Yeah, well, it's like saying that Newark counts as New York. It's not.

Speaker A
Yeah, but it's the same state. It's like a suburb of Detroit.

Speaker B
Yeah, I would not say that. I'm from Detroit.

Speaker A
No, that's fair. Are you from Ann Arbor?

Speaker B
No, I'm not from Ann Arbor either.

Speaker A
Yeah.

Speaker B
More from Ann Arbor than from Detroit, though.

Speaker A
Wait a second. Detroit. Here it is.

Speaker B
What are you looking at?

Speaker A
I'm just looking at the map to see where everything is. Oh, yeah.

Speaker B
I mean, it's close, but it's not at all the same.

Speaker A
Yeah. If any of these suburbs were its own city, like, Ann Arbor and Flint would be their own cities. Yeah, but they're very close.

Speaker B
Yeah. And even looking at the metro area here, you see Pontiac up there. That's, like, very distinctly its own city.

Speaker A
Yeah. Interesting.

Speaker B
Yeah. A lot of the ones closer in are just suburbs that oh.

Speaker A
I did not know Ipsalini was so close to both Ann Arbor and Detroit.

Speaker B
It is. Yeah. I mean, it's very close to Ann Arbor. It's still pretty far from Detroit.

Speaker A
Well, I mean, it's like, in between them. I thought it was kind of out in the middle of nowhere.

Speaker B
No, ann Arbor almost just transitions to Ipsalani.

Speaker A
Yeah. Wow, look at that. And then your airport DTW. Detroit is like, equidistant, almost from the center of Ann Arbor and the center of Detroit.

Speaker B
Yeah. It's half an hour from either place.

Speaker A
Yeah. That's pretty convenient.

Speaker B
Yeah. Unless you're like, going to downtown Detroit, but right. That's true. I think all airports are half an.

Speaker A
Hour from downtown, wherever there are a couple of exceptions.

Speaker B
Except LaGuardia, which is just horrible.

Speaker A
Yeah. Have you ever been to Toronto? I love talking about the Toronto Airport. We did a podcast about the I think we did. Anyway, it's really good. And Logan in Boston is also very close to city.

Speaker B
Oh, that's true. Yeah.

Speaker A
But those are, like, exceptions to the rule rather than maps. Boston, logan and Reagan's close, too. Reagan's not super far in DC.

Speaker B
That's true.

Speaker A
But they make up for it by Dulles being just an absolute shit show to get to.

Speaker B
I don't know if I've ever flown to the Boston Airport. I've been to Boston, but via bus or train.

Speaker A
Yeah.

Speaker B
Or both. I haven't spent much time in Boston. We should do a podcast. We need to talk about U of M basketball game at at 09:20 p.m..

Speaker A
You've got a hard out?

Speaker B
I have a hard out. It's the national championship game. I don't really watch that much sports, but we're playing Villanova for the NCAA Championship tonight. This is the last game of March Madness.

Speaker A
Nice. This is it.

Speaker B
This is it.

Speaker A
This is the big this is the one.

Speaker B
It's going to be Michigan or Villanova.

Speaker A
Nice. Where is Villanova?

Speaker B
That's a great question. I have no idea.

Speaker A
Villanova? Pennsylvania.

Speaker B
It's in Pennsylvania.

Speaker A
Apparently. It looks like a suburb of Philly in the same way that Ann Arbor is a suburb of Detroit. Don't at me.

Speaker B
I think Detroit. See, I think Ann Arbor is maybe further from Detroit. Doesn't have a good scale.

Speaker A
That was being funny.

Speaker B
Hilarious. Pennsylvania is a very long state.

Speaker A
Long state. I've driven across Pennsylvania many times. I used to live in Pittsburgh.

Speaker B
That's right. I've only driven across all of Pennsylvania once. Well, no, that's not true. Recently. I've only done it once.

Speaker A
Yeah.

Speaker B
A few years ago. It is. Yeah, me, too. Pittsburgh is cool.

Speaker A
Podcasting. Podcasting. Podcasting.

Speaker B
How does that work?

Speaker A
I actually have something that may be kind of fun to talk about.

Speaker B
Okay.

Speaker A
So I started code auditing this project and I started thinking about, like okay, when you're looking at a project, what are the things that you should fix? In what order? Right? Like, imagine you got put on a project and there could be any number of things wrong with it, right? There could be things that are physically just spelled wrong, like just English words that are spelled wrong. There could be implicitly interrupt optionals everywhere. There could be bad architecture decisions like singletons and stuff. There could be behavior that's incorrect. There could be a lack of tests. There could be all kinds of things wrong with it. Right. And every project has some subset of those things wrong with it.

Speaker B
Right. And a lot of these things are things that we have previously podcasted about in episodes one through 62.

Speaker A
Can you believe we've done 62 podcasts already?

Speaker B
It's kind of hard to believe, especially since we are doing every two weeks for a while. This is well over a year of I mean, how have we been doing this? Almost two years, right?

Speaker A
Yeah. This is the end of season four. We're getting towards the end of season four, which is the end of the second year. Yeah. Pretty nuts.

Speaker B
Yeah, it's been a pretty good run.

Speaker A
Yeah. So I was basically trying to go, what's the grand unified theory of, like, okay, I know I have these things wrong. What order should I tackle them in? What order is it important to fix them in? And so on.

Speaker B
Do you want to go first?

Speaker A
No, actually I'm curious to know what you think sort of unprompted, just as I introduced this topic to you like two minutes ago.

Speaker B
So with the caveat that it kind of depends whether you've been assigned anything specific to focus on. Right. If whoever's paying you wants you to focus on X thing, you should probably focus on that. What I would do is start using the app and note things that seem broken, look at feedback that you've gotten from users of the app and see what seems broken. Because I think rather than starting this with a technical or like code review, I would see, okay, are there obvious user facing problems? Are there subtle user facing problems? And then I would prioritize things that users are actually going to notice, like things that maybe you notice quickly when you start using the app and work from there. Because really, especially, I think on a contract engagement where maybe you're not there long, you're not going to be there super long, necessarily. I think the biggest bang for your buck is going to be, first of all, like, identifying what are the user facing problems here and then start digging into the code behind them. If they're like English fixes, I mean, maybe spend half an hour fixing all the english problems that you find in the app, right? That's a pretty easy win. If the app has problems like that, spelling errors and whatnot. And then you can start digging into your kind of prioritized list of problems that users can notice and you can start seeing what do we think the underlying causes are? Are any of these trivial to fix? If so, just knock those out really quickly. Then start digging in. Maybe some of the user facing problems are due to some more complicated, say like shared shared mutable state problem. Maybe they are related to singletons or any of the underlying problems that we've talked about before. Because the reason we talk about those things is not just because they're kind of code smells and they're not great, but because they do end up having user facing consequences, right? And so if I were just given an app and said here, improve this, I would start by trying to identify those consequences and then working backward and fixing trivial root causes and then starting to dig into, okay, these are the more complicated root causes that maybe are behind these. Users are facing problems. From there you can kind of prioritize what you want to work on based on how much time you have, based on how much time you think these things will take to fix. Another easy win would be if there are tests, run them. If tests are failing, then figure out why. Because someone wrote the test to assert that some behavior is happening and that behavior is not happening. So why is that test no longer valid? Something just broken. If there is a test suite, then there may be some easy wins to be had there as well. I think that would be my thought going in.

Speaker A
So what's super interesting is that your thoughts on this basically perfectly parallel mine.

Speaker B
Who would have thought that after doing 62 podcasts together?

Speaker A
Yeah, it's almost uncanny. Actually. What I have written down here is essentially the number one thing is that the behavior basically the behavior has to be correct. And when I say the behavior has to be correct, I mean sort of the happy path straight line, like nothing's going wrong. Behavior has to work. That is your first thing. And there may be other weird edge cases that don't work exactly as you expect them to. But that's a little less important than the core behavior of the app should just work. That's the first thing. If that doesn't work, you have to fix that first. There's nothing else to be done. Once you have that, then my thought is basically working on anything that is as you mentioned, you kind of go to the code level and you kind of work on anything that is trivial to fix, as you mentioned. So that's like spelling stuff that's punctuation in terms of like do we need semicolons here? Do we not need semicolons? Or like how do we define our closure syntax? Are we consistent in all of our syntax and how we write functions? And then of course, spacing, making sure that everything's spaced correctly.

Speaker B
I would say things like closure syntax and spacing are pretty far down the priority list here because assuming you've been handed an app, first and foremost you're trying to whip things into shape and maybe as you whip things into shape, you can make it more easily maintainable and easier to read. But that's not necessarily your first priority. Maybe your second or third priority is improving the maintainability and readability of the code base. And I guess you said that this is what you look at after you've knocked out a lot of the user facing stuff.

Speaker A
Yeah, the reason that I think that it's important to do early is because it can be so quick. And I'm actually going to explore some of this stuff in the next couple of weeks, but swiftly. Autocorrect and Swift format, which are two projects that will essentially let you automatically format everything in your project and just getting all that stuff to be sort of consistent, if that makes sense. So I think just because it can be automated and you can do it so quickly, I think there's some value in getting the whole code base in a very consistent format and cleaning up a bunch of things that are just obviously wrong and are distracting you from the subtler issues that are happening in the code base.

Speaker B
So I'll buy cleaning up things that are obviously wrong. But one kind of word of caution here, if we're talking about just going in and reformatting the code base, especially with an automated tool, is that you lose the ability then to say, display git blame in a sidebar in your editor, which can be really helpful as you dive into an unfamiliar code base, right? At least if people have been using git reasonably well, it can be very useful to go to a line of code, even if it's poorly formatted, but to be able to click and say, okay, why is this the way it is? What is written in this commit message? What poor request brought this in? And of course that history is still there, but it's a little bit harder to get to quickly if you have reformatted large parts of the code base.

Speaker A
Yeah, that's a really fair point. I didn't really think about that. That's a super good point. I would say that's also, like, I wish that weren't the case. It's a tooling problem, right? You should be able to see, okay, who edited this line of code last, but who edited before that? That seems really it would be cool.

Speaker B
You imagine like Sublime or IntelliJ or many ides will have, I guess does Xcode have any sort of like get blame tooling built right into the editor?

Speaker A
It does, but again, like all get blame tooling, it only goes one level. It only tells you who edited that line of code last.

Speaker B
This is what I'm thinking. You know how GitHub has a magic feature where if you're looking at diff, you add the get parameter w equals one to the URL and it ignores white space?

Speaker A
Yes.

Speaker B
It would be really cool if you could tell your Xcode, Sublime, IntelliJ, whatever you're using for your Git blame tool to basically ignore white space in that same way. Tell me the last non white space. Change to this line.

Speaker A
Right, that's a really cool ideaful. Change to this line.

Speaker B
Right.

Speaker A
That is a pretty cool idea too. Those are kind of tooling related questions that unfortunately we don't have those. So maybe you're right that white space needs to be saved until you have a better sense of how the app works. Or you could also just leave it, keep a reference, tap back to that original commit maybe on a branch, and then hop back to that whenever you want to do a get blame and figure out why is something the way it is? Sure, you have good commit messages, but for me it can sometimes be really hard to look at a code base when it's like when there's not the right spacing around a colon or something like that. And I think that that's kind of a personal failing of mine. And I know other people have this, but I think if I didn't have it, it would be better.

Speaker B
I mean, sure, that's a personal thing, but also that's the reason that we aim for consistent style is just because it makes the code easier for everyone to read. And if your brain is spending less time focusing on reading the code, you can spend more time just thinking about the code and what it's doing and what it says.

Speaker A
Yeah, exactly. So whether or not you want to fix formatting and spelling and stuff is on the table. Also in IntelliJ, which is like the app code and Android studio thing, right? IntelliJ actually tells you when your things are misspelled. So we'll actually break up your tokens based on Camel case or whatever and tell you if things are misspelled. Don't we deserve that?

Speaker B
We do. Although with the caveat, I'm pretty sure that I've turned that off recently just because a lot of you abbreviate things in variable names and even if it's obvious in context, the spell checker flags it. And then I have stuff underlined that is kind of distracting.

Speaker A
Yeah, you should at least be able to say run through this and then ignore everything that I'm ignoring or something. You should be able to do something good there and it's not going to catch everything just like any spell checker. But could we get to have yeah, definitely that's one thing. So then once you have your formatting and your visual level stuff, then you can get one level more serious and you can start looking at basically what? I was talking about this with Brian Iris earlier and he was calling it Swift Idioms. So, like, making sure that you're using optionals correctly, making sure that you're using sequences correctly, making sure that you're using string handling, making sure you're using indices instead of integer offsets, like working within the way that Swift wants you to work, starting to fix that stuff. The biggest one here, of course, is optionals, just because making sure you have good optional usage. In my experience, one of my clients from two or three years ago, they had a bunch of crashes. Only 60% of their users were crash free. And we just fixed all the optional stuff and basically just didn't allow any more exclamation points in the app and went from 60% crash free to like 99.9% crash free.

Speaker B
Yeah.

Speaker A
If you write a Swift app the way Swift wants you write apps, it doesn't crash.

Speaker B
So this goes back to something I was trying to say earlier, which is that even though I suggest starting from the user's perspective, a lot of the things that you'll notice while looking at code that, again, especially aren't Swift Idioms or you're looking for things that are misuse of optionals. We look for not just because we think exclamation points are ugly right. But because there are things that we know can often lead to user facing problems. Right. We don't avoid shared mutable state just because it's ugly and kind of hard to deal with. Well, we do. Because it's hard to deal with. Right. And because that hard to deal with manifests itself in strange user facing bugs throughout the application.

Speaker A
Yeah. At the end of the day, if you had infinite budget and infinite time, you could do whatever you wanted, but you don't. And so you have to focus on things that actually matter and things that will sort of have an effect for the end user, with the exception of formatting code formatting. I think it help developers so much, just making it clear to understand exactly what's happening.

Speaker B
If it's going to help you understand the code that the user is seeing run, then, I mean, that can be worthwhile.

Speaker A
Yeah. So yeah, so, and I mean, I mean, I just really can't overstate how important it is to get optionals. Right. They're kind of hard to work with if you're not used to them. But as you write more Swift, you gain a ton of facility for how to work with them and how to dance around them. And once you do, your app just never has a null value. I just expect one. It never crashes. It's crazy. It's really unreal how much of a difference it makes.

Speaker B
Yeah. It really is a very valuable tool. One of the things that I'm finding really frustrating about writing Python now is that I don't have option types and so things are just sometimes none when I don't expect them to be. And I don't notice that until much later at Runtime. And I'm like, oh, wait, where did that value come from? I didn't know that was that's weird.

Speaker A
Do you have problems? So if you imagine none to be its own type right. And string to be its own type and to be its own type, what's really happening here is that you have a reference that can be both string and none. Like, it can hold two different types.

Speaker B
Yeah. And I mean, that's something that optional explicitly models in the form of a sum type, right.

Speaker A
No, yeah, I'm down for that. My question is just, do you ever have issues in Python with two different types? So do you ever have a situation where you have a variable and you thought it was holding an integer, but it's actually holding a string or something like that? Or is it only with some type?

Speaker B
Yeah, that confusion definitely happens at times, too. Especially between things that are strings that just contain an integer and things that are actually integers. We had a bug a week or two ago at work, which was causing some of our scans to fail occasionally. Turned out to be because there was a string format thing that was expecting an integer and was receiving a string containing an integer instead. And that's the nature of programming in such a like untyped languages. Yeah, well, like runtime typed languages.

Speaker A
Right, right. Yeah. Okay, cool. Yeah. So I was basically just wondering, do you have problems with string and none only or string and int as well?

Speaker B
So that sounds, in my experience so far, experience with string and none, like, just things being missing is a little more common than things being the wrong type.

Speaker A
Right.

Speaker B
Although things definitely are types that I don't expect sometimes, too. It's annoying when that happens and I lose half an hour to it or more.

Speaker A
Yeah, I mean, type systems are good. Two people who like strong type systems.

Speaker B
Like strong type systems, enforced type systems.

Speaker A
That's right, yeah. That's a good summary for this podcast. People that like type systems. Like type systems.

Speaker B
So looping back to what you're doing. So you've looked for user facing things, spelling errors, code formatting. You're looking for Swift Idioms and code smells like not using optionals correctly. Right. Have you looked at anything else yet? Are there things that you're planning to look at next?

Speaker A
Well, I'm kind of like as I'm auditing this code base, I'm looking for all these things, but I'm kind of talking more about, okay, give me three months, what will I fix over that time?

Speaker B
Okay. Yeah.

Speaker A
Right? And so this is the order, sort of, in which I would fix it. So after you get Idioms figured out, then the next thing after that, I think it's time to start talking about architecture.

Speaker B
Okay.

Speaker A
So at that point, that's when you start looking at, okay, where do responsibilities belong? Are my classes too long? Do I have too many singletons. How can I restructure things in order to make them behave better, be able to model fewer bugs, all kinds of things like that.

Speaker B
I think that makes sense. I might even move some of this stuff again, like checking for how singletons are used, for example, sooner than checking how sequences get used. Right. Because at least in my experience, using singletons is more likely to lead to user facing bugs than using sequences in a weird way or something like that.

Speaker A
Yeah, my thinking here is that sequences is a weird one. Mostly when I talk about subsidiaries, I mostly mean optionals. There are very few cases where you are going to want to work at the sequence level. But when that happens, I think you should do it right. There's also something that I don't know if it should be folded in there, which is like are you mapping correctly? Like are you just creating a mutable array and then appending items to it that have been transformed and they're returning that array? That should just be a map and what's the right time to kind of address that and fix a lot of those? Because there are situations where that can improve the code reading. It improves performance because map knows how to reserve a certain capacity in an array. It also makes code easier to read and lets bugs have fewer places to hide in stuff like that. I don't really know if that belongs in the Idiom level, but I want to put it there. But I think of that as a different set of questions than architecture.

Speaker B
Okay. Stuff like that. Maybe. I would personally say it's worth looking at that if the app has a performance problem. Otherwise, I don't know, I get the instinct to fix things like that. But also, depending on the timeline you have, there may be higher priorities or like maybe there aren't. Maybe the app is in pretty good shape. But I don't know if I see that as quite as high of a priority.

Speaker A
Yeah. At some point it becomes time to work on architecture. Right. And that, I think, is actually the biggest chunk. It has a bunch of smaller subchunks in it. So that is teasing apart responsibilities. I mentioned basically figuring out in your optional handling step, you may have made a bunch of things optional that you then realize, like, actually this really shouldn't be optional. This is kind of crucial to the identity of this type and without it, the type shouldn't really exist. And so you can go deal with a couple of those things, dealing with who owns what, dealing with. And then of course, singleton is a big problem in lots and lots of apps. Design of classes, design of functions, that kind of thing. And then just jumping ahead a little bit. The last thing that this leads you to, the last thing I have written here is that is tests I was.

Speaker B
Going to ask about this at some point. Yeah.

Speaker A
Because as you change your architecture, you can then change it in a way that it can be tested, especially if it's like very logic heavy.

Speaker B
Right?

Speaker A
Yeah. And I kind of think you can't really do tests before architecture. You can maybe do it concurrently, but you can't really do it before, and you can't really do tests some you can.

Speaker B
So it depends what you're working on. Right. If you're cleaning up a lot of things that are in view controllers or view code, that's just not that testable to start with on iOS, because of the way that UI kit works out. Depending how the app is structured, though, and depending where you're fixing bugs, you may be able to add not a comprehensive test suite for a given class, but depending what it is, I would look for opportunities to write a failing test around whatever bug or whatever behavior you're changing. It definitely is something that in a lot of iOS apps, that's not likely to be very easy in most cases for many bugs, even bugs in logic heavy code. But yeah, as you notice, especially as you start refactoring things more fundamentally, that's a really good opportunity to improve testability and to add tests to make sure that you're not introducing new bugs while you're doing this.

Speaker A
Yeah, the only place that I would push back there is like, obviously the tests have to hit some API surface, and if you're going to be changing the API surface soon anyway, then does it really make sense to write tests against an API that's going to change because you know it's wrong? That would be the only place I'd push back there.

Speaker B
It's hard to answer. Sort of like a hypothetical abstract question. Right. But it depends on how you're planning to change that API service. It depends on whether expectations around that API are changing. It depends on whether client, how significantly clients of that API are going to change to match the new API. If your clients aren't going to change that much to match the new API, then your tests probably shouldn't need to change that much either. If you're totally throwing something out and introducing something with different behavior, then maybe just write tests around the behavior that you want.

Speaker A
Well, where I'm coming from is that tests are really good when your interface stays exactly the same, but your implementation changes. That's like the slam dunk case for when to write a test. But if your interface is going to change, then when the implementation changes and you run the test again and you see that it passes again, you can be really confident that your implementation change didn't mess anything up. Whereas if your interface changes as well, all of a sudden you're rewriting your test at the same time that you're rewriting your thing. And I feel like that can lead to that could definitely lead. To issues?

Speaker B
Well, it depends how the interface again, how substantially the interface is changing. Right. Yeah.

Speaker A
So I'm imagining taking a function that lives on a type and then moving it into its own type that does a thing, or taking some subset of properties and functions from a type and then extracting into its own thing and they're reusing that in multiple places. That's the kind of thing I'm thinking about.

Speaker B
Yeah. In those cases, that can still be right. You may need to move a test around or write a test, a single test that covers whatever logic you're deduplicating. But even if you need to change around a function signature or change around the type that's being tested, if the expectations are similar, and again, if you're adjusting a test in the same way that you're adjusting client code that uses whatever API you're testing, I think it's still generally a positive to have that. If the code is in such a state that you can actually do that.

Speaker A
Right. Okay, I think I'm following. I think that makes sense.

Speaker B
Right. This isn't going to make sense in every case. Obviously, if you're ripping this code out and totally and splitting this one function into two functions in two different places that do different things yeah. You're not going to reuse the same test for that.

Speaker A
Right.

Speaker B
If you're moving a function from one type to another, the function probably still does the same thing. Right. Even if the setup is a little bit different. Like you instantiate object B instead of object A and then call B my function.

Speaker A
Right. Yes.

Speaker B
Like in that sort of case, your API isn't really changing that much.

Speaker A
Right. And another idea I had is like, okay, one way to test it to make sure is okay, so say you have object a has some functionality. You want to extract an object b, extracting the object b, but then call it from object A. And then before you've done that, you've actually written a test for A. And so you maintain that A keeps its API contract. And then as long as those tests are passing, then you can go write tests for b as well.

Speaker B
Sure. Yeah.

Speaker A
And that way you can be sure that you're not changing the implementation and the interface at the same time and writing a test that could fail for reasons other than that the code is wrong.

Speaker B
Yeah. And it's also worth noting just in a lot of iOS code that you find out there, it's not likely to be easy to test and it may not be worth making the changes that are required to make the code testable and then refactoring it. It may be worth just making your best effort at changes and then making sure that they work. That it works, right.

Speaker A
Yeah.

Speaker B
And trying to get tests around the new code that you've written, at least.

Speaker A
Yeah. So this was my rough approach of like, okay, if you're in a code base and you want to fix stuff, what should you focus on, in what order? And I thought it was kind of a weird result that I ran into because it starts from things that are trivial and quick to do and ends up with things that are complicated and take a long time. I didn't know if that was good or bad. That's kind of the conclusion part of the episode.

Speaker B
Sure. I think that's good if you have things like taking the extreme trivial case, if there are spelling errors in the app that users are going to notice that and that's going to be really.

Speaker A
Functions, I mean, in functions and types and stuff. Yeah. Nobody's ever going to see that.

Speaker B
It's weird. Right. I get that instinct, especially if it's like a short term contract gig. I would really try to prioritize technical problems that are going to result in user facing improvements or in at least subtle user facing improvements. And I don't know how incompatible that really is with what you're saying. Right. Because again, a sort of through arc that I really want to drive home with this entire podcast, all 60 some episodes, is that we're not talking about software development principles in a vacuum. We're not talking about them or we're not talking about the single responsibility principle in a vacuum. We're not talking about singleton's in a vacuum.

Speaker A
It's not code for the sake of code.

Speaker B
Right. It's code for the sake of doing stuff on a user's phone or in a user's web browser. Right.

Speaker A
Being useful.

Speaker B
And so you can go about this by trying to identify user facing problems using the app. You can look at code smells, look at violations of these principles and best practices and prioritize by the likely impact that users will see because of them. And those are kind of two sides of the same coin. Right. Technical problems, violations of best practices are not isolated from what the user sees in our software.

Speaker A
Yeah. They're related.

Speaker B
Yeah. So if you have trivial things that you can fix that will make an impact for the user, whether it's a performance impact that they might notice, whether it's fixing a crash bug, whether it's something in between and that's an easy fix, then do that. If it's just like rearranging code for the sake of code, then maybe see if there are more important wins for you to go for.

Speaker A
Right. And I mean, I think moving code for the sake of moving code can be valuable. I think that that I would call yak Shaving as opposed to Bike shedding. Right. Bike Shedding. I would consider something where you're arguing about something that is simple and will affect a lot of people but ultimately is a pretty straightforward decision and someone should just make it. Yak Shaving is about doing a bunch of work up front that you don't necessarily know is going to lead you anywhere. Good but you have a good feeling that it will take you somewhere good. And when you do it, what happens to me? I don't want to give any numbers or anything, but what happens to me feels like enough times for me to trust my gut is that you change some stuff and then you realize as you're changing and moving some stuff around, you realize, oh, these pieces of code are actually kind of the same thing. And if I could abstract this one component from it, then I could build a more robust testable whatever layer underneath them both and then build them both on top of that and end up with a code base that's better. And you end up like you just kind of like I don't know. This is a very different point than the rest of this episode was kind of making, but I think yak shaving can be nice.

Speaker B
It can be and it can definitely have benefits. I would just caution that if there are things that are more clear wins to do in the near term, maybe do those before you start shaving your yaks.

Speaker A
Yeah. And I think part of yak shaving that makes it really great is that it can be really quick and then that quickness can show you something that you can see before.

Speaker B
Yeah.

Speaker A
If you're going to spend two weeks yak shaving something, maybe think about that a little bit harder before you start. But if it's going to be like 20 or 30 minutes or an hour long yak shave and you come to some realization or some epiphany about your code at the end of it, that.

Speaker B
Seems super worthwhile, I'll definitely grant you that I was thinking of yak shaving as typically being a longer process. Right. Like you're like a week later you find yourself like, writing your own UI framework for iOS on OpenGL or something that's probably not worth doing, but for your contract app that's probably not worth doing. If you're spending like 30 minutes improving some code and learning about the project, then yeah, go for it.

Speaker A
Yeah. Checks out. Yeah. So that's the rough framework I came up with for thinking about how to work in a new code base and thinking about what things would be worth tackling.

Speaker B
Yeah. I wonder. One of the things that you noted before we wrap up one of the things that you noted is that some of this stuff is a lot of things that you look for are things that you see just kind of based on experience and gut feeling. Do we have useful advice for people who maybe haven't been writing Swift quite as long and maybe don't have quite as developed, like a gut feeling? And I'm trying to think what what I would say in this case.

Speaker A
Yeah, I mean, I think frankly, like the back to work esque, like the butcher who always knows that the meat is two pounds even before they weigh it. Experience is super valuable, and that is what experience gets you if you don't have that experience. Part of what helped me, especially in the early days, is like looking at stuff and thinking about it and getting this feeling like, hey, and when I say feeling, I don't mean like from experience. I mean just I was like two years into writing code and I was like, something about this is wrong. I couldn't really express why it's wrong, but something doesn't seem right here. And kind of listening to that feeling and listening to that idea of like, well, I've read these things here and they maybe apply, but I can't really tell. But whatever's going on here, something's not right. And oftentimes posts on my blog, if I posted something in 2017, I maybe was thinking about it for four years before I figured out how to express it in a way that makes sense. So sometimes this stuff takes time to figure out. It just does. But I think listening to that gut and thinking like, okay, something weird is going on here. I don't know what it is yet. I don't know how long it's going to take me to figure out what it is, but I know that I don't like this.

Speaker B
Yeah. I'm going to also say maybe it's a balance between using the app and looking for things that seem off and reading the code and looking for things that seem off. And obviously both of these are useful tools. Maybe if you don't have quite as developed a gut sense for Swift Idioms, but you're using the app and you know, these things seem like similar but have subtly different behavior, that seems really weird. Maybe that's a jumping off point for you to start digging into that area of the code and seeing what's going on, and maybe you end up finding some similar but duplicate code via something like that too.

Speaker A
Yeah. Another thing I would say is if there's a part of the code that keeps breaking, it may not be written the best way.

Speaker B
Yeah.

Speaker A
Not only might have bugs, but it may be written in such a way that it tends towards bugs. And we actually like another contract that I'm on had a very similar situation where there was this piece of code that just kept failing. And I was like, you know what? I don't think we're thinking about this right. I think we just have to blow it up and try a totally different approach. And I opened a pull request for that today and fingers crossed that it works.

Speaker B
Fingers crossed.

Speaker A
Fingers crossed. Yeah. But yeah, if something breaks over and over again, maybe worth checking.

Speaker B
Like, yeah, absolutely.

Speaker A
Could we write this better? Is there a better way to model this? Is there a better way to think about this? Well, cool episode.

Speaker B
Yeah.

Speaker A
I'm going to grab some of this pizza in my fridge.

Speaker B
I'm going to go watch Michigan basketball game. Go, Blue.

Speaker A
Sounds good. Talk to you soon.

